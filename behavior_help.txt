0. All code is in ~/Desktop/Katrina/behavior_code/behavior.R. So source() that in.
	> source("~/Desktop/Katrina/behavior_code/behavior.R")
   Make sure before doing this that the stringr library is installed and that
   bootstrap_tests_June2013_STABLE.R is available. Additionally, if you plan to
   run the coxph test on latencies, make sure that the survival library is
   installed.
   For development, you can source("~/startup.R") instead to get a nice dataset to use.

1. Start with .getDataBatch().
	If you have score logs from more than one group, put the logs from each group
	in their own folder, then put all the folders in directory <folderPath> and call:
		> my_data <- .getDataBatch(folderPath, groups = TRUE)
	If you only have one group, put them all in directory <folderPath> and call:
		> my_data <- .getDataBatch(folderPath, groups = FALSE)
   Either way, make sure the logs are the only .txt files in the given directory.
   Follow the prompts to either use the start of video as the assay start for all logs,
   or select a mark left in the logs to be used as the assay start. Saving a mark as
   a default will result in all logs with that mark using it as an assay start. You can
   have more than one default at a time.

   The prompts will then direct you to check and see if you have duplicated behaviors. If
   you already have a cleaning function, skip this step (see step 3 for more information).

   Finally, you can enter your assay length to exclude behaviors that occur past the end
   of the assay. For example, for a 30-minute assay you could enter 1800.

2. If you have more than one log belonging to the same assay (for example, if you have a
   long video that got split up into chunks), call
	> my_data <- .stitchLogsTogether(my_data)
   and follow the prompts to combine all the logs for each assay.

3. Sort your data into groups by calling
	> my_data <- .pairGroups(my_data)
   Follow the prompts to tell the program how many experimental groups you measured at how
   many timepoints. You must do this EVEN IF you had only one experimental group at one
   timepoint.

   If you had more than one timepoint, you may wish to provide a function to match up logs
   across timepoints:
	> my_data <- .pairGroups(my_data, my_pair_fn)
   my_pair_fn should take as its first parameter a log name from the first timepoint
   (preceded by a folder and a slash) and as its second parameter a character vector of
   log names from any one followup timepoint (again preceded by their folder and a slash).
   It should return the log name from the character vector that is the followup log for
   the log given as the first parameter. For examples of this, see .pairLogsAustin() and
   .pairLogsRosa().

4. Edit your data if desired. To pair up two start-only behaviors into a single durational
   behavior (for example "pot entry" and "pot exit", call
	> my_data <- .makeDurationalBehaviorAll(my_data, "pot entry", "pot exit").
   This function will also rename the "end" behavior (ie, "pot exit") to match the start
   behavior.

   If you have behaviors you would like to rename or combine, call .replaceBehAll(). For
   example, to change "Female follows" to "Female Follows", we would call
	> my_data = .replaceBehAll(my_data, "Female follows", "Female Follows")
   If you do this manually instead of in step 1, call
	> my_data = .filterDataList(my_data, renameSubjects = TRUE)
   to make sure you did not introduce any ambiguity in which subject a particular behavior
   belongs to.

   You can also filter your data using .filterDataList(). This function has a LOT of
   options - see documentation in behavior.R for a complete list. Here are some examples
   of what you might want to use it for:
	Ignore approaches.
		> my_data_NoApproach <- .filterDataList(my_data, toExclude = c("Approach male", "Approach female"))
	Change "Lead" and "Quiver" from durational behaviors into start-only behaviors.
		> my_data <- .filterDataList(my_data, startOnly = c("Lead", "Quiver"));
   Obviously there are other uses, but there are too many combinations to include them
   all :)
   
   You can also write a function specifically for a given batch of data to clean it up. For
   examples of this, see .cleanUpMariana() and .cleanUpPGF2a().

5. Run .compareBasicStats() on your data. This function outputs several .csv files that can be
   opened in Excel:
	1. "<outfilePrefix>_<GROUPNAME>_data.csv" for each group, which contains the
	   counts, latencies, total duration, and average duration of each behavior
	   for each fish in the group; and
	2. "<outfilePrefix>_stats.csv", which contains the average and standard deviation
	   for each group of the counts, latencies, and durations of each behavior. It also
	   has p-values for each measure.
	3. JPGs of the plots produced by the bootstrap function
   Example function call:
	> .compareBasicStats(my_data, "~/Desktop/myExperiment");

   If there are fewer than <minNumLogs> observations for a given behavior, the stats will
   be skipped with a warning. The default for this parameter is 3, but you can raise it or
   lower it.
   
   By default, p-values are computed with a student t-test, a wilcox rank test, and an
   independent bootstrap test with means (which outputs a JPG for each behavior with
   histograms and box-and-whisker plots). To pass in your own set of stats tests, use
   the tests parameter.
   For example, to use just the t-test and the wilcox test, you could call
   	> .compareBasicStats(my_data, "~/Desktop/myExperiment", tests = list(ttest = t.test, wilcox = wilcox.test)

   By default, latencies are compared with a coxph test. IF YOUR ASSAYS WERE DIFFERENT
   LENGTHS (ie, time-censored at different times) THIS WILL NOT WORK!!!! To compare latencies
   with a different test, use the parameter latTests just like tests above.

   The functions you use MUST take the data as parameters x and y, and MUST return the
   p value as an item named "p.value" in a list. If you're not sure what that last sentence
   meant and you're having trouble, find Katrina or Austin for help. For more information
   about passing arguments to these passed-in functions, see the documentation for .runStats.

6. Compare entropies and transitional probabilities. The function calls should be:
	> .compareTransitionalProbabilities(my_data, outfilePrefix = "~/Desktop/myExperiment")
   and
	> .compareEntropy(my_data, "~/Desktop/myExperiment")
   These functions have mostly the same options as .calcBasicStats. It's also
   potentially desirable to call them on .filterDataList(my_data, startOnly = T). Just
   like .calcBasicStats(), they output .csv's of raw data and statistics.

   If you want to have the probability of each transition be (count transition) / (total
   num transitions), rather than the default (count transition) / (count leader), add the
   parameter byTotal=TRUE to .compareTransitionalProbabilities(). Also, you can use
   .filterDataList() with any of the options in the next step (startOnly, subject,
   boutInterval, etc.) to directly compare two markov chains that show something other
   than just raw transitional probabilities.

7. Make Markov chains. There are several options for this. The most common is 
   .makeGroupDotPlots(), which outputs one markov chain graph for each group. Example
   function call:
	> .makeGroupDotPlots(my_data, "~/Desktop/unmodified_markov", minValForLine = .02)
   minValForLine is definitely one of the more important parameters. Only lines that
   represent a probability greater than minValForLine will be drawn (here, 2%). The
   parameter byTotal is exactly the same as for the probability matrices.
   All the fancy Markov chains are done by passing through optional parameters that go
   to .filterData.
	For example, to only get behaviors from five minutes into the video to ten minutes
	into the video, you would call:
		> .makeGroupDotPlots(my_data, "~/Desktop/0510_markov", minValForLine = .02, startTime = 300, endTime = 600)
   	To get a Markov chain for just male behaviors:
		> .makeGroupDotPlots(my_data, "~/Desktop/male_markov", minValForLine = .02, subject="male")
  	To only include the starts of durational behaviors:
		> .makeGroupDotPlots(my_data, "~/Desktop/startonly_markov", minValForLine = .02, startOnly=T)
	To call any pause of 10 seconds the start of a new bout:
		> .makeGroupDotPlots(my_data, "~/Desktop/10sbout_markov", minValForLine = .02, boutInterval = 10)
   Any of these options can be combined with each other. To get a complete list, look at
   the comment for .filterData.

   The other relevant functions are .makeDotPlotsFromProbMas, which directly takes the
   output of .groupLevelProbMats (be sure to tell it whether you used byTotal or not!),
   and .makeDotPlots(), which functions similarly to .makeGroupDotPlots except that it
   draws a separate markov chain for each fish in the group rather than making a single
   markov chain representing the probability matrix for the entire group.

   You will need to have GraphViz installed to open and view your Markov chains.

8. Make a color key. To do this, call
   	> my_color_key <- .buildColorKey(names(.findDupBehaviors(my_data)))
   and follow the prompts. This will make a color key that is suitable for raster plots; to
   make one suitable for behavioral density graphs, call
	> my_color_key <- .buildColorKey(names(.findDupBehaviors(.filterDataList(my_data, renameStartStop = T))))

9. Make raster plots. To do this, call
        > .makeMulticolorRasterPlots(my_data, "~/Desktop/myExperiment", my_color_key)
   This makes a separate raster plot for each experimental group and outputs the color key
   used. There are a ton of options for this function:
    (a) Graphics options.
	<wiggle> controls how much height the durational behavior bars are allowed to
	take up. It should always be between 0 and 0.5 (default 0.2)
	<defaultDur> is the width (in seconds) of the tick marks (default 2)
	<durationalBehs> is a vector of behaviors that should be plotted as bars instead
	of tick marks. Default is all behaviors scored as durational.
	<staggerSubjects> if TRUE causes male behaviors to be plotted above the line
	for a subject and female behaviors to be plotted below the line. (default FALSE)
	<widthInInches> and <rowHeightInInches> control the dimensions of the output plot.
	<horizontalLines> if TRUE causes a horizontal black line is drawn behind the
	raster plot for each subject. (default FALSE)
    (b) Align at the nth occurance of a behavior. For example, the first spawn:
	> .makeMulticolorRasterPlots(my_data, "~/Desktop/myExperiment", my_color_key, zeroBeh = "spawning")
	The fifth quiver:
	> .makeMulticolorRasterPlots(my_data, "~/Desktop/myExperiment", my_color_key, zeroBeh = "quiver", zeroBeh.n = 5)
	The first aggressive behavior:
	> .makeMulticolorRasterPlots(my_data, "~/Desktop/myExperiment", my_color_key, zeroBeh = c("bite", "chase", "display"))
	With these, the assay start will automatically be marked as a black tick.
    (c) Sort by something. To do this, you need a sortAttribute. For example, to sort by
	number of quivers, you could do
	> my_sortAttribute = .getCountAttribute("quiver", my_data)
	There are also functions .getLatencyAttribute(), .getTotalDurAttribute(), and
	.getAverageDurAttribute().
	
	Alternatively, you can sort by outside data, such as GSI or hormone levels. To do
	this, you will need to call
	> supplementalData <- read.csv("~/Desktop/my_data_file.csv");
	Then check the contents of supplemental data to make sure there are no weird extra
	rows, and you have the columns you thought you had. You should have one column with
	subject names (say "Assay.name") and one with your data of interest (say "GSI"). Then
	call
	> my_sortAttribute = .getAttributeFromSupplementalData(supplementalData, my_data, "GSI", nameCol = "Assay.name");

	Once you have your sortAttribute, call
	> .makeMulticolorRasterPlots(my_data, "~/Desktop/myExperiment", my_color_key, sortAttribute = my_sortAttribute, sort.name = "GSI");
	<sort.name> should obviously be whichever attribute you sorted by; it could just as
	easily be "Number of quivers". Additionally, you can add sort.decreasing = T to
	sort in decreasing order, and/or sort.na.last = F to put NAs first or
	sort.na.last = NA to exclude NA values of your attribute.

10.Make Behavioral Density plots by calling .behavioralDensityGraphs(), which makes one graph
   for each behavior in <targetBehs>, or each behavior in my_color_key if <targetBehs> is
   unspecified.
   Example function call:
	> .behavioralDensityGraphs(my_data, my_color_key, filePref = "~/Desktop/myExperiment")

   <weightingStyle> controls which actual values are plotted. It must be a value in
   c("density", "singlebeh", "allbeh", "centerbeh", "rawcounts"). If it is <density>, the output
   of built-in function density() is plotted; you can additionally specify <densityBW> (default 1)
   which is the bandwidth in seconds of the density calculations, and <densityN> (default 512),
   which is the number of points returned by the density() function.

   All the other values of this parameter yield histograms, with behaviors binned together in
   bins of width <secondsPerBin> (default 0.5). The exact value of the parameter controls what
   the counts in each bin are divided by to normalize them ("rawcounts" yields no normalization).
   "allbeh" divides by the total number of behaviors for that subject, "singlebeh" divides by the
   count in that subject's log of the behavior the line represents, and "centerbeh" divides by
   the count in that subject's log of <centerBeh>.


   Other important parameters:
	lim = 20      # plot 20 seconds before and after the center behavior (default 15)
	lineWidth = 4	# 4-pixel-thick lines
	lineType = "dashed"	# dashed lines
	ymax = 1	# y-axis goes to 1 for all plots, regardless of actual values.
   
   To skip plotting a given behavior, just remove it from my_color_key. If you are proficientish
   in R, the easiest way to do this is with something like
   	> .behavioralDensityGraphs(my_data, my_color_key[-c(1,4,5),], filePref = "~/Desktop/behdensityplots/")
   If you can't make this work, just generate another color key from step 7 with this
   behavior skipped by entering "none".

   You can also call .behavioralDensityGraph() directly to plot a single graph centered at
   <centerBeh> without separating by group.

11. TODO follow up on leads! (how?)


Get Things in R

1. Get probability matrices. For a single fish:
	> pm_1 <- .getProbabilityMatrix(.filterData(my_data[[1]], renameStartStop = TRUE))
   To get probability matrices combined by group:
	> probMatsByGroup <- .groupLevelProbMats(my_data)
   If you want to have the probability of each transition be (count transition) / (total
   num transitions), rather than the default (count transition) / (count leader), add the
   parameter byTotal=TRUE to either of these function calls.

2. Get entropy. To compute entropy separately for each fish, then find the average for
   each group, call
	> .groupLevelEntropy(my_data)
   To find the entropy of the combined probability matrices for each group, call
	> lapply(probMatsByGroup, function(d){.computeEntropyProbMatrix(d$probMat)$h_norm})


   

12. Other Relevant Information (for development)
Other functions that are archaic, untested, incomplete, etc. are at the bottom of the file.

.getAllContexts() is the start of what will eventually be used to make branching diagrams.
.sepGroups() is THE FUNCTION to use if you are implementing anything, really; it separates
	the fish by experimental group and extracts a list of all the behavior names.

To-do items are marked TODO in the code file, so they are super easy to edit-find. They are
usually listed right before the relevant function.

TROUBLESHOOTING COMMON ERRORS AND ISSUES:
Is there a weird character in a behavior name? ie '/', ':', '\', '{', '}', etc.
Do you need to filter your data to be startOnly or renameStartStop?
Are you giving this function a single data frame (one log) or a list?
Have you called .stitchLogsTogether() if applicable and .pairGroups()?
